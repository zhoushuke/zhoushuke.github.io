<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic%7CRoboto+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhoushuke.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头 不定期更新">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes学习(Kubernetes踩坑记)">
<meta property="og:url" content="https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/index.html">
<meta property="og:site_name" content="Z.S.K.&#39;s Records">
<meta property="og:description" content="记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头 不定期更新">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20220106144313.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20211118152201.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210622102036.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210428190009.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210307212429.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/image-20210302200255132.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210106185555.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201223232538.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201223233150.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201112171302.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201017221807.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200909154834.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200908211841.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902132758.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902123531.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200901183122.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902101139.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200827183609.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200827184435.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430132115.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430132148.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/41B2684F-312C-41ED-AF56-D6014C6B74E6.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430145913.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/63611F8A-F803-46F5-8792-67111E03DF91.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/FB66ABBE-FF79-48A4-8A8B-7FDC3AED6634.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/ACEB6BE6-7E22-4A43-AB4A-A51E00CE9EFE.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/5FECFF57-F204-4ADF-A9E0-5F1D9A917194.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/447313AF-7DD6-4FB4-8F46-AE1DC468C7CA.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/C73EB07F-14CD-43A7-86C0-49B4812F57A6.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/2AE46262-2624-446C-909E-1FA0E76A8AD7.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506115705.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506115805.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506120151.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506120040.png">
<meta property="og:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200511180743.png">
<meta property="article:published_time" content="2024-12-25T11:30:53.000Z">
<meta property="article:modified_time" content="2024-12-31T03:07:38.319Z">
<meta property="article:author" content="周淑科">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png">


<link rel="canonical" href="https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/","path":"2024/12/25/Kubernetes-prombles/","title":"Kubernetes学习(Kubernetes踩坑记)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Kubernetes学习(Kubernetes踩坑记) | Z.S.K.'s Records</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Z.S.K.'s Records</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/ZSK-Profile.pdf" rel="section"><i class="fa fa-user fa-fw"></i>简历</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-commonweal"><a href="/404.html" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%B9%E5%99%A8%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8F%90%E7%A4%BA-cpuset-cpus-permission-denied"><span class="nav-number">1.</span> <span class="nav-text">容器启动时提示:cpuset.cpus: permission denied</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%97%A5%E5%BF%97%E6%8A%A5%E9%94%99-unable-to-fetch-container-log-stats"><span class="nav-number">2.</span> <span class="nav-text">kubelet日志报错: unable to fetch container log stats</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%97%A5%E5%BF%97%E9%94%99%E8%AF%AF-Unable-to-create-endpoint-status-429"><span class="nav-number">3.</span> <span class="nav-text">kubelet日志错误: Unable to create endpoint (status 429)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E4%B8%AD%E6%8F%90%E7%A4%BA-no-relationship-found-between-node-xxx-and-this-object"><span class="nav-number">4.</span> <span class="nav-text">kubelet中提示: no relationship found between node xxx and this object</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-controller-manager%E6%97%A5%E5%BF%97%E5%87%BA%E7%8E%B0-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1"><span class="nav-number">5.</span> <span class="nav-text">kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8F%90%E7%A4%BAFailed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id"><span class="nav-number">6.</span> <span class="nav-text">kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#prometheus-logs-compaction-failed-%E5%AF%B9%E6%95%B0%E7%9A%84%E6%80%A7%E8%B4%A8uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page"><span class="nav-number">7.</span> <span class="nav-text">prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#is-forbidden-User-xxx-cannot-get-resource-%E2%80%9Cservices-x2F-proxy%E2%80%9D"><span class="nav-number">8.</span> <span class="nav-text">is forbidden: User xxx cannot get resource “services&#x2F;proxy”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pod%E7%8A%B6%E6%80%81%E6%8F%90%E7%A4%BAUnexpectedAdmissionError"><span class="nav-number">9.</span> <span class="nav-text">pod状态提示UnexpectedAdmissionError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nvidia-device-plugin-%E6%8F%90%E7%A4%BAbind-address-already-in-use"><span class="nav-number">10.</span> <span class="nav-text">nvidia-device-plugin 提示bind: address already in use</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#prometheus%E6%8F%90%E7%A4%BA-x2F-metrics-x2F-resource-x2F-v1alpha1-404"><span class="nav-number">11.</span> <span class="nav-text">prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Error-from-server-Forbidden-pods-%E2%80%9Cxxx%E2%80%9D-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container"><span class="nav-number">12.</span> <span class="nav-text">Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubeadm-join%E6%8F%90%E7%A4%BAunable-to-fetch-the-kubeadm-config-ConfigMap"><span class="nav-number">13.</span> <span class="nav-text">kubeadm join提示unable to fetch the kubeadm-config ConfigMap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRD-spec-versions-Invalid-value"><span class="nav-number">14.</span> <span class="nav-text">CRD spec.versions: Invalid value</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0%E9%99%A4namespaces%E6%97%B6Terminating%EF%BC%8C%E6%97%A0%E6%B3%95%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E4%B8%94%E6%97%A0%E6%B3%95%E5%9C%A8%E8%AF%A5ns%E4%B8%8B%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1"><span class="nav-number">15.</span> <span class="nav-text">删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#docker-%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8F%90%E7%A4%BAno-sockets-found-via-socket-activation"><span class="nav-number">16.</span> <span class="nav-text">docker 启动时提示no sockets found via socket activation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prometheus-opening-storage-failed-invalid-block-sequence"><span class="nav-number">17.</span> <span class="nav-text">Prometheus opening storage failed: invalid block sequence</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%8F%90%E7%A4%BA-The-node-was-low-on-resource-ephemeral-storage"><span class="nav-number">18.</span> <span class="nav-text">kubelet提示: The node was low on resource: ephemeral-storage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubectl%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97%E6%97%B6%E6%8F%90%E7%A4%BA-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout"><span class="nav-number">19.</span> <span class="nav-text">kubectl查看日志时提示: Error from server: Get https:&#x2F;&#x2F;xxx:10250&#x2F;containerLogs&#x2F;spring-prod&#x2F;xxx-0&#x2F;xxx: dial tcp xxx:10250: i&#x2F;o timeout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service%E8%A7%A3%E6%9E%90%E6%8F%90%E7%A4%BA-Temporary-failure-in-name-resolution"><span class="nav-number">20.</span> <span class="nav-text">Service解析提示 Temporary failure in name resolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Kubectl%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%97%B6%E6%8F%90%E7%A4%BA-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0"><span class="nav-number">21.</span> <span class="nav-text">使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted"><span class="nav-number">22.</span> <span class="nav-text">namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unknown-field-volumeClaimTemplates"><span class="nav-number">23.</span> <span class="nav-text">unknown field volumeClaimTemplates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CoreDNS%E6%8F%90%E7%A4%BALoop-127-0-0-1-38827-gt-53-detected-for-zone-%E2%80%9C-%E2%80%9D"><span class="nav-number">24.</span> <span class="nav-text">CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hostPath-volumes-are-not-allowed-to-be-used"><span class="nav-number">25.</span> <span class="nav-text">hostPath volumes are not allowed to be used</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root"><span class="nav-number">26.</span> <span class="nav-text">container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OCI-runtime-create-failed-no-such-file-or-directory"><span class="nav-number">27.</span> <span class="nav-text">OCI runtime create failed: no such file or directory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%95%9C%E5%83%8F%E6%8B%89%E5%8F%96%E6%97%B6%E5%87%BA%E7%8E%B0ImageInspectError"><span class="nav-number">28.</span> <span class="nav-text">镜像拉取时出现ImageInspectError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%97%A5%E5%BF%97%E6%8F%90%E7%A4%BA-node-not-found"><span class="nav-number">29.</span> <span class="nav-text">kubelet日志提示: node not found</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OCI-runtime-create-failed-executable-file-not-found-in-PATH"><span class="nav-number">30.</span> <span class="nav-text">OCI runtime create failed: executable file not found in PATH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nginx-Ingress-Empty-address"><span class="nav-number">31.</span> <span class="nav-text">Nginx Ingress Empty address</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet-but-volume-paths-are-still-present-on-disk"><span class="nav-number">32.</span> <span class="nav-text">kubelet: but volume paths are still present on disk</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PLEG-is-not-healthy"><span class="nav-number">33.</span> <span class="nav-text">PLEG is not healthy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metrics-server-10255-connection-refused"><span class="nav-number">34.</span> <span class="nav-text">metrics-server: 10255 connection refused</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metrics-server-no-such-host"><span class="nav-number">35.</span> <span class="nav-text">metrics-server: no such host</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pod%E6%97%A0%E6%B3%95%E8%A7%A3%E6%9E%90%E5%9F%9F%E5%90%8D"><span class="nav-number">36.</span> <span class="nav-text">pod无法解析域名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Are-you-tring-to-mount-a-directory-on-to-a-file"><span class="nav-number">37.</span> <span class="nav-text">Are you tring to mount a directory on to a file</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubernetes%E5%90%AF%E5%8A%A8%E5%90%8E%E6%8F%90%E7%A4%BAslice-no-such-file-ro-directory"><span class="nav-number">38.</span> <span class="nav-text">Kubernetes启动后提示slice: no such file ro directory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%9Ccni0%E2%80%9D-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx"><span class="nav-number">39.</span> <span class="nav-text">“cni0” already has an IP address different from xxx.xxxx.xxx.xxx</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubeadm%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%8F%90%E7%A4%BA-CPU%E5%B0%8F%E4%BA%8E2"><span class="nav-number">40.</span> <span class="nav-text">kubeadm初始化时提示 CPU小于2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unable-to-update-cni-config-no-network-found"><span class="nav-number">41.</span> <span class="nav-text">Unable to update cni config: no network found</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#while-reading-%E2%80%98google-dockercfg%E2%80%99-metadata"><span class="nav-number">42.</span> <span class="nav-text">while reading ‘google-dockercfg’ metadata</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#no-providers-available-to-validate-pod-request"><span class="nav-number">43.</span> <span class="nav-text">no providers available to validate pod request</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unable-to-upgrade-connection-Unauthorized"><span class="nav-number">44.</span> <span class="nav-text">unable to upgrade connection: Unauthorized</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubectl-get-cs-%E6%8F%90%E7%A4%BA-lt-unknown-gt"><span class="nav-number">45.</span> <span class="nav-text">kubectl get cs 提示&lt;unknown&gt;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85kubeadm%E6%97%B6%E6%8F%90%E7%A4%BADepends%E9%94%99%E8%AF%AF"><span class="nav-number">46.</span> <span class="nav-text">安装kubeadm时提示Depends错误</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BF%E9%97%AEservice%E6%97%B6%E6%8F%90%E7%A4%BAConnection-refused"><span class="nav-number">47.</span> <span class="nav-text">访问service时提示Connection refused</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#error-converting-fieldPath-field-label-not-supported"><span class="nav-number">48.</span> <span class="nav-text">error converting fieldPath: field label not supported</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0"><span class="nav-number">49.</span> <span class="nav-text">参考文章:</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="周淑科"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">周淑科</p>
  <div class="site-description" itemprop="description">Better Later Than Never</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">219</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="周淑科">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Z.S.K.'s Records">
      <meta itemprop="description" content="Better Later Than Never">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Kubernetes学习(Kubernetes踩坑记) | Z.S.K.'s Records">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kubernetes学习(Kubernetes踩坑记)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-12-25 19:30:53" itemprop="dateCreated datePublished" datetime="2024-12-25T19:30:53+08:00">2024-12-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Kubernetes/" itemprop="url" rel="index"><span itemprop="name">Kubernetes</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>17k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>15 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头</p>
<p><strong>不定期更新</strong></p>
<span id="more"></span>

<h3 id="容器启动时提示-cpuset-cpus-permission-denied"><a href="#容器启动时提示-cpuset-cpus-permission-denied" class="headerlink" title="容器启动时提示:cpuset.cpus: permission denied"></a>容器启动时提示:cpuset.cpus: permission denied</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubelet Error: unable to apply cgroup configuration: failed to write <span class="string">&quot;10-11&quot;</span>: write /sys/fs/cgroup/cpuset/kubepods/burstable/xxx/yyy/cpuset.cpus: permission denied\&quot;<span class="string">&quot;: unknown</span></span><br></pre></td></tr></table></figure>
<p>原因: 宿主机上有裸机进程占用了kubelet能够使用的cpu，由于kubelet对这些被占用的cpu不感知，导致kubelet在分配cpu时刚好又分配了这部分被占用的cpu<br>解决: 释放这些被裸机进程占用的cpu，重启Kubelet</p>
<h3 id="kubelet日志报错-unable-to-fetch-container-log-stats"><a href="#kubelet日志报错-unable-to-fetch-container-log-stats" class="headerlink" title="kubelet日志报错: unable to fetch container log stats"></a>kubelet日志报错: unable to fetch container log stats</h3><p>原因: 当将cri从docker切换为containerd后，会在kubelet pod目录下遗留cri还是docker时link文件, 会导致kubelet在运行过程中一直尝试去读取这类日志，但这些日志已经指向了不存在的路径，所以无法fetch<br>解决: 将这些目标路径不存在的link文件直接删除即可</p>
<h3 id="kubelet日志错误-Unable-to-create-endpoint-status-429"><a href="#kubelet日志错误-Unable-to-create-endpoint-status-429" class="headerlink" title="kubelet日志错误: Unable to create endpoint (status 429)"></a>kubelet日志错误: Unable to create endpoint (status 429)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unable to create endpoint: response status code does not match any response statuses defined <span class="keyword">for</span> this endpoint <span class="keyword">in</span> the swagger spec (status 429)</span><br></pre></td></tr></table></figure>

<p>原因: 并发创建的pod数太多触发了cilium的api-rate-limit配置上限, 更详细的说明可参考以下链接<br>解决: 参考<a target="_blank" rel="noopener" href="https://izsk.me/2024/08/10/cilium-on-kubernetes-errors-apiratelimit/">cilium在kubernetes中的生产实践六(cilium排错指南)之api-rate-limit</a></p>
<h3 id="kubelet中提示-no-relationship-found-between-node-xxx-and-this-object"><a href="#kubelet中提示-no-relationship-found-between-node-xxx-and-this-object" class="headerlink" title="kubelet中提示: no relationship found between node xxx and this object"></a>kubelet中提示: no relationship found between node xxx and this object</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">User <span class="string">&quot;system:node:xxx&quot;</span> cannot list resource <span class="string">&quot;configmap&quot;</span> <span class="keyword">in</span> API group <span class="keyword">in</span> the namespace <span class="string">&quot;xxx&quot;</span>, no relationship found between node xxx and this object</span><br></pre></td></tr></table></figure>

<p>原因: 由于集群开启了Node Authorization Mode,所以节点上的kubelet能操作的权限是跟节点上运行pod相关联的，可以通过以下的方式验证</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录到节点kubectl</span></span><br><span class="line">kubectl --kubeconfig=/etc/kubernetes/kubelet.conf -n xxx can-i list cm/xxx</span><br><span class="line"><span class="comment"># 如果有权限则提示yes, 没有则为no</span></span><br></pre></td></tr></table></figure>

<p>解决:  如果需要访问，则可通过一个pod挂载对应的cm调度到该节点上，那么在这个node上即可通过kubelet访问到相关的cm</p>
<p>参考:  </p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://enix.io/fr/blog/kubernetes-tip-and-tricks-node-authorization-mode/">Kubernetes : Le Node Authorization Mode de l&#39;API-Server</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.frognew.com/2021/05/k8s-apiserver-authorization-mode-node.html">kubernetes apiserver的node鉴权 | 青蛙小白</a></p>
</li>
</ol>
<h3 id="kube-controller-manager日志出现-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1"><a href="#kube-controller-manager日志出现-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1" class="headerlink" title="kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1"></a>kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1</h3><p>原因: apiservice存在Failed的service</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get apiservice</span><br><span class="line"><span class="comment"># 查看是否存在ServiceNotFound, 删除对应的service即可</span></span><br><span class="line">kubectl delete apiservice &#123;name&#125;</span><br></pre></td></tr></table></figure>

<h3 id="kubelet启动时提示Failed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id"><a href="#kubelet启动时提示Failed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id" class="headerlink" title="kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id"></a>kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id</h3><p>原因: kubelet的数据目录存在脏容器数据</p>
<p>解决: 使用以下命令找到脏容器，删除后重启kubelet</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 894f35dca3eda57adef28b69acd0607efdeb34e8814e87e196bc163305576028 是上面报错中的ID</span></span><br><span class="line">docker ps -a --filter <span class="string">&quot;label=io.kubernetes.sandbox.id=894f35dca3eda57adef28b69acd0607efdeb34e8814e87e196bc163305576028&quot;</span></span><br><span class="line"><span class="comment"># 根据上述ID删除容器</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">rm</span> ID</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启kubelet</span></span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>

<h3 id="prometheus-logs-compaction-failed-对数的性质uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page"><a href="#prometheus-logs-compaction-failed-对数的性质uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page" class="headerlink" title="prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page"></a>prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page</h3><p>原因: prometheus在对wal进行压缩时出现segment错误，导致创建checkout失败</p>
<p>解决: 在prometheus持久化目录下删除上述xxxx的目录，然后重启prometheus</p>
<p>重启后可能会出现unexpected gap to last checkpoint, expect: xxx, requested: yyy</p>
<p>需要将checkout目录也进行删除，然后重启prometheus实例 </p>
<h3 id="is-forbidden-User-xxx-cannot-get-resource-“services-x2F-proxy”"><a href="#is-forbidden-User-xxx-cannot-get-resource-“services-x2F-proxy”" class="headerlink" title="is forbidden: User xxx cannot get resource “services&#x2F;proxy”"></a>is forbidden: User xxx cannot get resource “services&#x2F;proxy”</h3><p>在rancher中使用非admin用户无法显示grafana的 workload metrics, 请求中提示: services http:rancher-monitoring-grafana:80 is forbidden: User xxx cannot get resource “services&#x2F;proxy” in API group “” in the namespace cattle-monitoring-system</p>
<p>原因: 需要为该用户在cattle-monitoring-system ns中授权 services&#x2F;proxy权限, 同时该用户所对应的角色需要继承 project-monitoring-view角色，这样非admin用户才能看到metrics菜单</p>
<p>参考: <a target="_blank" rel="noopener" href="https://forums.rancher.com/t/cluster-member-cant-see-use-grafana-or-monitoring-stuff/15814">https://forums.rancher.com/t/cluster-member-cant-see-use-grafana-or-monitoring-stuff/15814</a></p>
<h3 id="pod状态提示UnexpectedAdmissionError"><a href="#pod状态提示UnexpectedAdmissionError" class="headerlink" title="pod状态提示UnexpectedAdmissionError"></a>pod状态提示UnexpectedAdmissionError</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png"></p>
<p>原因: 在排查的过程中，发现这个问题涉及的东西太多，写了篇专门的文章来说明这个问题，可参考<a target="_blank" rel="noopener" href="https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError/">Kubernetes-pod-status-is-UnexpectedAdmissionError</a></p>
<h3 id="nvidia-device-plugin-提示bind-address-already-in-use"><a href="#nvidia-device-plugin-提示bind-address-already-in-use" class="headerlink" title="nvidia-device-plugin 提示bind: address already in use"></a>nvidia-device-plugin 提示bind: address already in use</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20220106144313.png"></p>
<p>原因: 这个错误提示其实是有歧义的, 一般看到<code>bind: address already in use</code>都会认为是不是地址端口被占用了, 在这里其实不是，正常来讲<code>nvidia-device-plugin</code>在正常退出后会将节点上的<code>nvidia.sock</code>文件一起删除，启动时会自动创建该文件, 但如果出现退出后<code>nvidia.sock</code>文件还存在，这个时候启动<code>nvidia-device-plugin</code>就会提示上述报错</p>
<p>解决: 手动删除节点上的<code>nvidia.sock</code>,然后重启<code>nvidia-device-plugin</code>即可</p>
<h3 id="prometheus提示-x2F-metrics-x2F-resource-x2F-v1alpha1-404"><a href="#prometheus提示-x2F-metrics-x2F-resource-x2F-v1alpha1-404" class="headerlink" title="prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404"></a>prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20211118152201.png"></p>
<p>原因: 这是因为[&#x2F;metrics&#x2F;resource&#x2F;v1alpha1]是在v1.14中才新增的特性，而当前kubelet版本为1.13</p>
<p>解决: 升级k8s的版本，这里要注意的是<strong>kubelet的版本不能为api-server的高，所以不能只升级kubelet.</strong></p>
<h3 id="Error-from-server-Forbidden-pods-“xxx”-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container"><a href="#Error-from-server-Forbidden-pods-“xxx”-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container" class="headerlink" title="Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container"></a>Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container</h3><p>原因: 排查两个方面，是否有psp，第二个是否启用了相关的admission</p>
<p>解决: 在本case中，因安全因素，开启了DenyEscalatingExec 这个admission，从api-server的配置–enable-admission-plugins中上去掉DenyEscalatingExec 即可</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/</a></p>
<h3 id="kubeadm-join提示unable-to-fetch-the-kubeadm-config-ConfigMap"><a href="#kubeadm-join提示unable-to-fetch-the-kubeadm-config-ConfigMap" class="headerlink" title="kubeadm join提示unable to fetch the kubeadm-config ConfigMap"></a>kubeadm join提示unable to fetch the kubeadm-config ConfigMap</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">discovery</span>] <span class="string">Successfully</span> <span class="string">established</span> <span class="string">connection</span> <span class="string">with</span> <span class="string">API</span> <span class="string">Server</span> <span class="string">&quot;xxx.xxx.xxx.xxx:16443&quot;</span></span><br><span class="line">[<span class="string">join</span>] <span class="string">Reading</span> <span class="string">configuration</span> <span class="string">from</span> <span class="string">the</span> <span class="string">cluster...</span></span><br><span class="line">[<span class="string">join</span>] <span class="attr">FYI:</span> <span class="string">You</span> <span class="string">can</span> <span class="string">look</span> <span class="string">at</span> <span class="string">this</span> <span class="string">config</span> <span class="string">file</span> <span class="string">with</span> <span class="string">&#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span></span><br><span class="line"><span class="attr">unable to fetch the kubeadm-config ConfigMap: failed to get config map: Get https://127.0.0.1:16443/api/v1/namespaces/kube-system/configmaps/kubeadm-config: dial tcp 127.0.0.1:16443: connect:</span> <span class="string">connection</span> <span class="string">refused</span></span><br></pre></td></tr></table></figure>

<p>原因: 127.0.0.1:16443是apiserver的VIP,从报错信息来看, 对127.0.0.1:16443的访问被拒绝了, 但是在apiserver本地curl这个地址又是没问题的，还是非常诡异，可以通过以下方式解决了</p>
<p>解决: 请确认好kubeadm join时会访问的两个配置文件中的apiserver地址是否正确</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get cm kubeadm-config -oyaml</span><br><span class="line"><span class="comment"># 其中的controlPlaneEndpoint地址</span></span><br><span class="line"></span><br><span class="line">kubectl edit cm cluster-info -oyaml -n kube-public</span><br><span class="line"><span class="comment"># 其中的server地址</span></span><br></pre></td></tr></table></figure>

<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubeadm/issues/1596">https://github.com/kubernetes/kubeadm/issues/1596</a></p>
<h3 id="CRD-spec-versions-Invalid-value"><a href="#CRD-spec-versions-Invalid-value" class="headerlink" title="CRD spec.versions: Invalid value"></a>CRD spec.versions: Invalid value</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210622102036.png"></p>
<p>原因: CRD yaml文件中apiVersion与versions中的版本不对应</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/">https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/</a></p>
<h3 id="删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象"><a href="#删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象" class="headerlink" title="删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象"></a>删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210428190009.png"></p>
<p>原因: ns处于terminating时hang住了，使用<code>--grace-period=0 -- force</code>强制删除也无效</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存现在的ns json</span></span><br><span class="line">kubectl get ns xxxx -o json &gt; /tmp/temp.json</span><br><span class="line"><span class="comment"># 编辑temp.json，将其中的spec.finalizer字段删除保存</span></span><br><span class="line"><span class="comment"># 导出k8s访问密钥</span></span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep client-cert  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6) |<span class="built_in">base64</span> -d &gt; /tmp/client.pem</span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep client-key-data  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6 ) |<span class="built_in">base64</span> -d &gt; /tmp/client-key.pem</span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep certificate-authority-data  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6  ) |<span class="built_in">base64</span> -d &gt; /tmp/ca.pem</span><br><span class="line"><span class="comment"># 解决namespace Terminating，根据实际情况修改&lt;namespaces&gt;</span></span><br><span class="line">curl --cert /tmp/client.pem --key /tmp/client-key.pem --cacert /tmp/ca.pem -H <span class="string">&quot;Content-Type: application/json&quot;</span> -X PUT --data-binary @/tmp/temp.json https://xxx.xxx.xxx.xxx:6443/api/v1/namespaces/&lt;namespaces&gt;/finalize</span><br></pre></td></tr></table></figure>

<h3 id="docker-启动时提示no-sockets-found-via-socket-activation"><a href="#docker-启动时提示no-sockets-found-via-socket-activation" class="headerlink" title="docker 启动时提示no sockets found via socket activation"></a>docker 启动时提示no sockets found via socket activation</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210307212429.png"></p>
<p>解决: 在start docker前先执行<code>systemctl unmask docker.socket</code>即可</p>
<h3 id="Prometheus-opening-storage-failed-invalid-block-sequence"><a href="#Prometheus-opening-storage-failed-invalid-block-sequence" class="headerlink" title="Prometheus opening storage failed: invalid block sequence"></a>Prometheus opening storage failed: invalid block sequence</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/image-20210302200255132.png"></p>
<p>原因: 这个需要排查prometheus持久化目录中是否存在时间超出设置阈值的时间段的文件，删掉后重启即可</p>
<h3 id="kubelet提示-The-node-was-low-on-resource-ephemeral-storage"><a href="#kubelet提示-The-node-was-low-on-resource-ephemeral-storage" class="headerlink" title="kubelet提示: The node was low on resource: ephemeral-storage"></a>kubelet提示: The node was low on resource: ephemeral-storage</h3><p>原因: 节点上kubelet的配置路径超过阈值会触发驱逐，默认情况下阈值是85%</p>
<p>解决: 或者清理磁盘释放资源，或者通过可修改kubelet的配置参数<code>imagefs.available</code>来提高阈值,然后重启kubelet.</p>
<p>参考: <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1456389">https://cloud.tencent.com/developer/article/1456389</a></p>
<h3 id="kubectl查看日志时提示-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout"><a href="#kubectl查看日志时提示-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout" class="headerlink" title="kubectl查看日志时提示: Error from server: Get https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx: dial tcp xxx:10250: i&#x2F;o timeout"></a>kubectl查看日志时提示: Error from server: Get <a target="_blank" rel="noopener" href="https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx">https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx</a>: dial tcp xxx:10250: i&#x2F;o timeout</h3><p>原因: 目地机器的iptables对10250这个端口进行了drop，如下图</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables-save -L INPUT –-line-numbers</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20210106185555.png"></p>
<p>解决: 删除对应的规则 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -D INPUT 10</span><br></pre></td></tr></table></figure>

<h3 id="Service解析提示-Temporary-failure-in-name-resolution"><a href="#Service解析提示-Temporary-failure-in-name-resolution" class="headerlink" title="Service解析提示 Temporary failure in name resolution"></a>Service解析提示 Temporary failure in name resolution</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201223232538.png"></p>
<p>原因: 出现这种情况很奇怪，现象显示就是域名无法解析，全格式的域名能够解析是因为在pod的&#x2F;etc&#x2F;hosts中有全域名的记录,那么问题就出在于corddns解析上，coredns从日志来看，没有任何报错，但是从pod的状态来看，虽然处于Running状态，但是0&#x2F;1可以看出coredns并未处于ready状态.</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201223233150.png"></p>
<p>可以查看ep记录，会发现endpoint那一栏是空的，这也就证实了k8s把coredns的状态分为了notready状态，所以ep才没有记录，经过与其它环境比较后发现跟配置有关，最终定位在coredns的配置文件上,在插件上需要加上ready</p>
<p>解决: 在cm的配置上添加read插件，如下图</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ... 省略</span></span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health</span><br><span class="line">        ready  <span class="comment"># 加上该行后问题解决</span></span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          pods insecure</span><br><span class="line">          upstream /etc/resolv.conf</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="comment"># ... 省略</span></span><br></pre></td></tr></table></figure>

<p>关于coredns的ready插件的使用,可以参考<a target="_blank" rel="noopener" href="https://coredns.io/plugins/ready/">这里</a></p>
<p>总结起来就是使用ready来表明当前已准备好可以接收请求，从codedns的yaml文件也可以看到有<code>livenessProbe</code></p>
<h3 id="使用Kubectl命令行时提示-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0"><a href="#使用Kubectl命令行时提示-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0" class="headerlink" title="使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0"></a>使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0</h3><p>原因: 这个跟本地的go环境有关</p>
<p>解决: 在使用kubectl前使用命令<code>export GODEBUG=x509ignoreCN=0</code>即可</p>
<h3 id="namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted"><a href="#namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted" class="headerlink" title="namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted"></a>namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted</h3><p>原因: kube-system是集群中受保护的ns, 被禁止删除，主要是防止误操作，如果需要删除的话，可以使用–force</p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/62167/files">https://github.com/kubernetes/kubernetes/pull/62167/files</a></p>
<h3 id="unknown-field-volumeClaimTemplates"><a href="#unknown-field-volumeClaimTemplates" class="headerlink" title="unknown field volumeClaimTemplates"></a>unknown field volumeClaimTemplates</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201112171302.png"></p>
<p>原因: 提示这个错误的原因是资源对象是deployment, 而deployment本就是无状态的， 所以也就没有使用pv这一说法了，可以参考api</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps">deploymentspec-v1-apps</a></p>
<h3 id="CoreDNS提示Loop-127-0-0-1-38827-gt-53-detected-for-zone-“-”"><a href="#CoreDNS提示Loop-127-0-0-1-38827-gt-53-detected-for-zone-“-”" class="headerlink" title="CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”"></a>CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20201017221807.png"></p>
<p>原因: CoreDNS所在的宿主机上<code>/etc/resolv.conf</code>中存在有127.0.xx的nameserver,这样会造成解析死循环.</p>
<p>解决: 修改宿主机<code>/etc/resolv.conf</code>或者将CoreDNS的configmap中的forward修改为一个可用的地址, 如<code>8.8.8.8</code></p>
<h3 id="hostPath-volumes-are-not-allowed-to-be-used"><a href="#hostPath-volumes-are-not-allowed-to-be-used" class="headerlink" title="hostPath volumes are not allowed to be used"></a>hostPath volumes are not allowed to be used</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200909154834.png"></p>
<p>原因: 集群中存在psp禁止pod直接挂载hostpath.</p>
<p>解决: 通过添加以下的psp规则来允许或者删除存在的psp都可</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodSecurityPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">auth-privilege-psp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">allowedHostPaths:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">/</span></span><br><span class="line">  <span class="attr">fsGroup:</span></span><br><span class="line">    <span class="attr">ranges:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">      <span class="attr">min:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPorts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">9796</span></span><br><span class="line">    <span class="attr">min:</span> <span class="number">9796</span></span><br><span class="line">  <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">requiredDropCapabilities:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">  <span class="attr">runAsUser:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">seLinux:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">supplementalGroups:</span></span><br><span class="line">    <span class="attr">ranges:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">      <span class="attr">min:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">configMap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">emptyDir</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">projected</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">secret</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">downwardAPI</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">persistentVolumeClaim</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hostPath</span></span><br></pre></td></tr></table></figure>

<h3 id="container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root"><a href="#container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root" class="headerlink" title="container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root"></a>container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200908211841.png"></p>
<p>原因: 这是由于在deploy中设置了<code>securityContext: runAsNonRoot: true</code>, 在这种情况下，当pod启动时，使用的默认用户,比如上面的grafana，k8s无法确定他是不是root用户</p>
<p>解决: 指定<code>securityContext:runAsUser: 1000</code>, 随便一个id号即可, 只要不是0(0代表root)</p>
<p>参考: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51544003/using-runasnonroot-in-kubernetes">https://stackoverflow.com/questions/51544003/using-runasnonroot-in-kubernetes</a></p>
<h3 id="OCI-runtime-create-failed-no-such-file-or-directory"><a href="#OCI-runtime-create-failed-no-such-file-or-directory" class="headerlink" title="OCI runtime create failed: no such file or directory"></a>OCI runtime create failed: no such file or directory</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902132758.png"></p>
<p>原因: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pod下的数据目录已经损坏.</p>
<p>解决: 删除对应的目录即可</p>
<h3 id="镜像拉取时出现ImageInspectError"><a href="#镜像拉取时出现ImageInspectError" class="headerlink" title="镜像拉取时出现ImageInspectError"></a>镜像拉取时出现ImageInspectError</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902123531.png"></p>
<p>原因: 这种情况下一般都是镜像损坏了</p>
<p>解决: 把相关的镜像删除后重新拉取</p>
<h3 id="kubelet日志提示-node-not-found"><a href="#kubelet日志提示-node-not-found" class="headerlink" title="kubelet日志提示: node not found"></a>kubelet日志提示: node not found</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200901183122.png"></p>
<p>原因: 这个报错只是中间过程，真正的原因在于apiserver没有启动成功，导致会一直出现这个错误</p>
<p>解决: 排查kubelet与apiserver的连通是否正常</p>
<h3 id="OCI-runtime-create-failed-executable-file-not-found-in-PATH"><a href="#OCI-runtime-create-failed-executable-file-not-found-in-PATH" class="headerlink" title="OCI runtime create failed: executable file not found in PATH"></a>OCI runtime create failed: executable file not found in PATH</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200902101139.png"></p>
<p>原因: 在path中没有nvidia-container-runtime-hook这个二进制文件，可能跟本人删除nvidia显卡驱动有关.</p>
<p>解决: nvidia-container-runtime-hook是docker nvidia的runtime文件，重新安装即可.</p>
<h3 id="Nginx-Ingress-Empty-address"><a href="#Nginx-Ingress-Empty-address" class="headerlink" title="Nginx Ingress Empty address"></a>Nginx Ingress Empty address</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get ingress</span></span><br><span class="line">NAME         HOSTS                                       ADDRESS   PORTS   AGE</span><br><span class="line">prometheus   prometheus.1box.com                                   80      31d</span><br></pre></td></tr></table></figure>

<p>会发现address中的ip是空的，而查看生产环境时却是有ip列表的.</p>
<p>原因: 这个其实不是一个错误，也不影响使用，原因在于测试环境中是不存在LoadBalance类型的svc, 如果需要address中显示ip的话需要做些额外的设置</p>
<p>解决: </p>
<ol>
<li>在nginx controller的容器中指定启动参数<code>-report-ingress-status</code></li>
<li>在nginx controller引用的configmap中添加<code>external-status-address: &quot;10.164.15.220&quot;</code></li>
</ol>
<p>这样的话,在address中变会显示<code>10.164.15.220</code>了</p>
<p>参考:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/nginxinc/kubernetes-ingress/issues/587">https://github.com/nginxinc/kubernetes-ingress/issues/587</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/reporting-resources-status/">https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/reporting-resources-status/</a></p>
<h3 id="kubelet-but-volume-paths-are-still-present-on-disk"><a href="#kubelet-but-volume-paths-are-still-present-on-disk" class="headerlink" title="kubelet: but volume paths are still present on disk"></a>kubelet: but volume paths are still present on disk</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200827183609.png"></p>
<p>原因: 这种pod已经被删除了，但是volume还存在于disk中</p>
<p>解决: 删除对应的目录<code>/var/lib/kubelet/pods/3cd73...</code></p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/longhorn/longhorn/issues/485">https://github.com/longhorn/longhorn/issues/485</a></p>
<h3 id="PLEG-is-not-healthy"><a href="#PLEG-is-not-healthy" class="headerlink" title="PLEG is not healthy"></a>PLEG is not healthy</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200827184435.png"></p>
<p>原因: 宿主机上面跑的容器太多，导致pod无法在3m钟内完成生命周期检查</p>
<p>解决:  PLEG(Pod Lifecycle Event Generator)用于kublet同步pod生命周期，本想着如果是因为时间短导致的超时，那是不是可以直接调整这个时间呢? 查看kubelet的源码发现不太行，3m时间是写在代码里的因此无法修改，当然修改再编译肯定没问题，但成本太大，所以只得优化容器的调度情况.</p>
<p>参考: <a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/">https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/</a></p>
<h3 id="metrics-server-10255-connection-refused"><a href="#metrics-server-10255-connection-refused" class="headerlink" title="metrics-server: 10255 connection refused"></a>metrics-server: 10255 connection refused</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">unable to fully collect metrics:</span> [<span class="attr">unable to fully scrape metrics from source kubelet_summary:k8s-node-49:</span> <span class="string">unable</span> <span class="string">to</span> <span class="string">fetch</span> <span class="string">metrics</span> <span class="string">from</span> <span class="string">Kubelet</span> <span class="string">k8s-node-49</span> <span class="string">(xxx.xxx.xxx.49):</span> <span class="string">Get</span> <span class="string">http://xxx.xxx.xxx.49:10255/stats/summary?only_cpu_and_memory=true:</span> <span class="attr">dial tcp xxx.xxx.xxx.49:10255: connect:</span> <span class="string">connection</span> <span class="string">refused</span></span><br></pre></td></tr></table></figure>

<p>原因: 现在的k8s都默认禁用了kubelet的10255端口，出现这个错误是因此在kubelet启动命令中启用了该端口</p>
<p>解决: 将<code>- --kubelet-port=10255</code>注释</p>
<h3 id="metrics-server-no-such-host"><a href="#metrics-server-no-such-host" class="headerlink" title="metrics-server: no such host"></a>metrics-server: no such host</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">unable</span> <span class="string">to</span> <span class="string">fetch</span> <span class="string">metrics</span> <span class="string">from</span> <span class="string">Kubelet</span> <span class="string">k8s-node-234</span> <span class="string">(k8s-node-234):</span> <span class="string">Get</span> <span class="string">https://k8s-node-234:10250/stats/summary?only_cpu_and_memory=true:</span> <span class="attr">dial tcp: lookup k8s-node-234 on 10.96.0.10:53:</span> <span class="literal">no</span> <span class="string">such</span> <span class="string">host</span></span><br></pre></td></tr></table></figure>

<p>解决: 使用<code>kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</code>参数</p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md">https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md</a></p>
<h3 id="pod无法解析域名"><a href="#pod无法解析域名" class="headerlink" title="pod无法解析域名"></a>pod无法解析域名</h3><p>集群中新增了几台机器用于部署clickhouse用于做大数据分析，为了不让这类占用大量资源的Pod影响其它Pod，因此选择给机器打taint的形式控制该类Pod的调度, 创建Pod后发现这些Pod都会出现DNS解析异常, </p>
<p>原因； 要注意容器网络，比如这里使用的是flannel是否容忍了这些机器的taint，不然的话，flannel是无法被调度到这些机器的,因此容器间的通信会出现问题，<strong>可以将类似flannel这些的基础POD容忍所有的NoScheule与NoExecute</strong></p>
<p>解决: flannel的ds yaml中添加以下toleration，这样适用任何的场景</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoExecute</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">Exists</span></span><br></pre></td></tr></table></figure>

<h3 id="Are-you-tring-to-mount-a-directory-on-to-a-file"><a href="#Are-you-tring-to-mount-a-directory-on-to-a-file" class="headerlink" title="Are you tring to mount a directory on to a file"></a>Are you tring to mount a directory on to a file</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430132115.png"></p>
<p>原因:  Yaml文件中使用了subPath, 但是mountPath指向了一个目录</p>
<p>解决: mountPath需要加上文件名</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430132148.png"></p>
<h3 id="Kubernetes启动后提示slice-no-such-file-ro-directory"><a href="#Kubernetes启动后提示slice-no-such-file-ro-directory" class="headerlink" title="Kubernetes启动后提示slice: no such file ro directory"></a>Kubernetes启动后提示slice: no such file ro directory</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/41B2684F-312C-41ED-AF56-D6014C6B74E6.png"></p>
<p>原因: yum安装的kubelet默认的是cgroupfs，而docker一般默认的是systemd。但是kubernetes安装的时候建议使用systemd, kubelet跟docker的不一致, 要么修改kubelet的启动参数 , 要么修改dokcer启动参数</p>
<p>解决: </p>
<p>docker的启动参数文件为: <code>/etc/docker/daemon.json: &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd”]</code></p>
<p>kubelet的启动参数文件为: <code>/var/lib/kubelet/config.yaml:  cgroupDriver: systemd</code></p>
<h3 id="“cni0”-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx"><a href="#“cni0”-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx" class="headerlink" title="“cni0” already has an IP address different from xxx.xxxx.xxx.xxx"></a>“cni0” already has an IP address different from xxx.xxxx.xxx.xxx</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200430145913.png"></p>
<p>原因: 使用kubeadm reset 重复操作过, reset之后，之前flannel创建的bridge device cni0和网口设备flannel.1依然健在</p>
<p> 解决: 添加之前需要清除下网络</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop docker</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/cni/</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/kubelet/*</span><br><span class="line"><span class="built_in">rm</span> -rf /etc/cni/</span><br><span class="line">ifconfig cni0 down</span><br><span class="line">ifconfig flannel.1 down</span><br><span class="line">ifconfig docker0 down</span><br><span class="line">ip <span class="built_in">link</span> delete cni0</span><br><span class="line">ip <span class="built_in">link</span> delete flannel.1</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl start kubelet</span><br></pre></td></tr></table></figure>

<h3 id="kubeadm初始化时提示-CPU小于2"><a href="#kubeadm初始化时提示-CPU小于2" class="headerlink" title="kubeadm初始化时提示 CPU小于2"></a>kubeadm初始化时提示 CPU小于2</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">    [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br></pre></td></tr></table></figure>

<p>原因: kubeadm对资源一定的要求，如果是测试环境无所谓的话,可忽略</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用 --ignore-preflight-errors 忽略</span><br></pre></td></tr></table></figure>

<h3 id="Unable-to-update-cni-config-no-network-found"><a href="#Unable-to-update-cni-config-no-network-found" class="headerlink" title="Unable to update cni config: no network found"></a>Unable to update cni config: no network found</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/63611F8A-F803-46F5-8792-67111E03DF91.png"></p>
<p>原因: 还未部署网络插件容器，导致在&#x2F;etc&#x2F;cni下还没有文件</p>
<p>解决: 根据实际情况部署网络插件</p>
<h3 id="while-reading-‘google-dockercfg’-metadata"><a href="#while-reading-‘google-dockercfg’-metadata" class="headerlink" title="while reading ‘google-dockercfg’ metadata"></a>while reading ‘google-dockercfg’ metadata</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/FB66ABBE-FF79-48A4-8A8B-7FDC3AED6634.png"></p>
<p>原因: 从其它机器访问上述这些url确实出现 404</p>
<p>解决: 由于是在RKE上部署k8s, 所以可能会去访问google相关的url, 不影响业务,可以忽略</p>
<h3 id="no-providers-available-to-validate-pod-request"><a href="#no-providers-available-to-validate-pod-request" class="headerlink" title="no providers available to validate pod request"></a>no providers available to validate pod request</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/ACEB6BE6-7E22-4A43-AB4A-A51E00CE9EFE.png"></p>
<p>原因: 在api-server的启动参数enable-admission中设置了PodSecrityPolicy, 但是集群中又没有任何的podsecritypolicy，因此导致整个集群都无法新建出pod</p>
<p>解决: 删除相应的podsecritypolicy即可</p>
<h3 id="unable-to-upgrade-connection-Unauthorized"><a href="#unable-to-upgrade-connection-Unauthorized" class="headerlink" title="unable to upgrade connection: Unauthorized"></a>unable to upgrade connection: Unauthorized</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/5FECFF57-F204-4ADF-A9E0-5F1D9A917194.png"></p>
<p>原因: kubelet的启动参数少了x509认证方式</p>
<p>解决: 配置证书的路径, 加上重启kubelet即可</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/447313AF-7DD6-4FB4-8F46-AE1DC468C7CA.png"></p>
<h3 id="kubectl-get-cs-提示-lt-unknown-gt"><a href="#kubectl-get-cs-提示-lt-unknown-gt" class="headerlink" title="kubectl get cs 提示&lt;unknown&gt;"></a>kubectl get cs 提示&lt;unknown&gt;</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/C73EB07F-14CD-43A7-86C0-49B4812F57A6.png"></p>
<p>原因: 这是个kubectl的bug, 跟版本相关，kubernetes有意废除get cs命令</p>
<p>解决: 目前对集群的运行无影响, 可通过加-oyaml 查看状态</p>
<h3 id="安装kubeadm时提示Depends错误"><a href="#安装kubeadm时提示Depends错误" class="headerlink" title="安装kubeadm时提示Depends错误"></a>安装kubeadm时提示Depends错误</h3><p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/2AE46262-2624-446C-909E-1FA0E76A8AD7.png"></p>
<p>原因:  跟kubeadm没多大关系, 系统安装的有问题</p>
<p>解决: 执行以下命令修复</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt --fix-broken install </span><br><span class="line">apt-get update</span><br></pre></td></tr></table></figure>

<h3 id="访问service时提示Connection-refused"><a href="#访问service时提示Connection-refused" class="headerlink" title="访问service时提示Connection refused"></a>访问service时提示Connection refused</h3><p>现象: 从另一环境中把yaml文件导入到新环境后有些service访问不通</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">telnet mongodb-mst.external 27017</span><br><span class="line">Trying 10.97.135.242...</span><br><span class="line">telnet: Unable to connect to remote host: Connection refused</span><br></pre></td></tr></table></figure>

<p>首先排除了域名、端口的配置问题。</p>
<p>会发现提示连接拒绝.可以确定的是集群内的DNS是正常的.</p>
<p>那么就是通过clusterIP无法到达realserver. 查看iptables规则</p>
<p>发现提示<code>default has no endpoints --reject-with icmp-port-unreachable</code></p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506115705.png"></p>
<p>很奇怪, 提示没有endpoints, 但是使用<code>kubectl get ep</code>又能看到ep存在且配置没有问题</p>
<p>而且这个default是怎么来的.</p>
<p>为了方便部署, 很多配置是从别的环境导出的配置, 有些service访问是没问题的, 只有少部分<code>connection refused</code></p>
<p>结比一下发现一个很有趣的问题，先来看下不正常的yaml文件:</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506115805.png"></p>
<p>由于服务在集群外部署的, 因此这里使用了subset方式, 开始怀疑问题在这里, 但是后来知道这个不是重点</p>
<p>乍一看这个配置没什么问题, 部署也很正常, 但是对比正常的yaml文件，发现一个区别：</p>
<p>如果在services中的端口指定了名字, 那么在subsets中的端口也要带名字, 没有带名字的就会出现<code>connection refused</code>，这个确实之前从来没有关注过, 一个端口的情况下也不会指定名字</p>
<p>而且这面iptalbes中提示的default刚好就是这里的port name,虽然不敢相信，但是也只能试一试这个方法: 在subsets中也加了port name</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506120151.png"></p>
<p>重新部署一个，再次查看iptalbes规则 </p>
<p><code>iptables-save|grep mongodb-mst</code></p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200506120040.png"></p>
<p>OMG, 居然可行, 再看下telnet的结果:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Trying 10.105.116.92...</span><br><span class="line">Connected to mongodb-mst.external.svc.cluster.local.</span><br><span class="line">Escape character is <span class="string">&#x27;^]&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>访问也是没问题, 那么原因就在于:</p>
<p><strong>在service中指定了port name时, 也需要在ep中指定port name</strong></p>
<h3 id="error-converting-fieldPath-field-label-not-supported"><a href="#error-converting-fieldPath-field-label-not-supported" class="headerlink" title="error converting fieldPath: field label not supported"></a>error converting fieldPath: field label not supported</h3><p>今天遇到一个部署deployment出错的问题, yaml文件如下:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demo-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">4test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="comment"># The field we&#x27;ll use to couple our ConfigMap and Deployment</span></span><br><span class="line">        <span class="attr">configHash:</span> <span class="string">4431f6d28fdf60c8140d28c42cde331a76269ac7a0e6af01d0de0fa8392c1145</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-demo-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">gcr.io/optimum-rock-145719/config-demo-app</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">envFrom:</span></span><br><span class="line">        <span class="comment"># The ConfigMap we want to use</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">configMapRef:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">demo-config</span></span><br><span class="line">        <span class="comment"># Extra-curricular: We can make the hash of our ConfigMap available at a</span></span><br><span class="line">        <span class="comment"># (e.g.) debug endpoint via a fieldRef</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_HASH</span></span><br><span class="line">          <span class="comment">#value: &quot;4431f6d28fdf60c8140d28c42cde331a76269ac7a0e6af01d0de0fa8392c1145&quot;</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.template.metadata.annotations.configHash</span></span><br></pre></td></tr></table></figure>

<p>提示以下错误:</p>
<p><img src="https://raw.gitmirror.com/zhoushuke/BlogPhoto/master/githuboss/20200511180743.png"></p>
<p>会提示<code>Unsupported value:spec.template.metadata.annotations.configHash</code></p>
<p>目的很简单: container中的环境变量中引用configHash变量, 这个值是当configmap变更时比对两个不同的sha值以此达到重启pod的目的, 但fieldPath显然不支持<code>spec.template.metadata.annotations.configHash</code></p>
<p>从报错提示来看, 支持列表有<code>metadata.name, metadata.namespace, metadata.uid, spec.nodeName,spec.serviceAccountName, status.hostIp, status.PodIP, status.PodIPs</code></p>
<p>这些值用于容器中需要以下信息时可以不从k8s的apiserver中获取而是可以很方便地从这些变量直接获得</p>
<p>参考: </p>
<p><a target="_blank" rel="noopener" href="https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern">https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern</a></p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/</a></p>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章:"></a><strong>参考文章:</strong></h3><blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://izsk.me/2024/08/10/cilium-on-kubernetes-errors-apiratelimit/">cilium在kubernetes中的生产实践六(cilium排错指南)之api-rate-limit</a></li>
<li><a target="_blank" rel="noopener" href="https://enix.io/fr/blog/kubernetes-tip-and-tricks-node-authorization-mode/">Kubernetes : Le Node Authorization Mode de l&#39;API-Server</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/docs/en/cloud-private/3.2.0?topic=console-namespace-is-stuck-in-terminating-state">https://www.ibm.com/docs/en/cloud-private/3.2.0?topic=console-namespace-is-stuck-in-terminating-state</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/">https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/19317">https://github.com/kubernetes/kubernetes/issues/19317</a></li>
<li><a target="_blank" rel="noopener" href="http://www.xuyasong.com/?p=1725">http://www.xuyasong.com/?p=1725</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/">https://kubernetes.io/</a></li>
<li><a target="_blank" rel="noopener" href="https://fuckcloudnative.io/">https://fuckcloudnative.io/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/breezey/p/8810039.html">https://www.cnblogs.com/breezey/p/8810039.html</a></li>
<li><a target="_blank" rel="noopener" href="https://ieevee.com/tech/2018/04/25/downwardapi.html">https://ieevee.com/tech/2018/04/25/downwardapi.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern">https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps">https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/62167/files">https://github.com/kubernetes/kubernetes/pull/62167/files</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md">https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubeadm/issues/1596">https://github.com/kubernetes/kubeadm/issues/1596</a></li>
<li><a target="_blank" rel="noopener" href="https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError">https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError</a></li>
</ul>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>Buy Me a Coffee</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpayme.png" alt="周淑科 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipayme.jpg" alt="周淑科 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>周淑科
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/" title="Kubernetes学习(Kubernetes踩坑记)">https://zhoushuke.github.io/2024/12/25/Kubernetes-prombles/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请保留原文作者及链接！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Kubernetes/" rel="tag"># Kubernetes</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/12/25/2024/" rel="prev" title="再见2024,2025再见">
                  <i class="fa fa-angle-left"></i> 再见2024,2025再见
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/12/31/%E5%8D%9A%E5%AE%A2%E6%96%B0%E5%8A%9F%E8%83%BD2025/" rel="next" title="博客新功能2025">
                  博客新功能2025 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">周淑科</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>站点总字数：</span>
    <span title="站点总字数">985k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span>站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">14:55</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://cn.vercount.one/js"></script>





</body>
</html>
